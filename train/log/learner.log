2025-07-01 19:42:52.173121: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-01 19:42:52.180246: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2025-07-01 19:42:52.219766: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2025-07-01 19:42:52.221512: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-07-01 19:42:53.113894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2025-07-01 19:42:54.274 | INFO | PID:200 | trainer.__init__:32 - learner train process start at pid is 200
2025-07-01 19:42:54.278 | INFO | PID:200 | replay_buffer_wrapper.__init__:58 - learner train replaybuff, use reverb
[reverb/cc/platform/tfrecord_checkpointer.cc:162]  Initializing TFRecordCheckpointer in /tmp/tmpev2e6_3g.
[reverb/cc/platform/tfrecord_checkpointer.cc:567] Loading latest checkpoint from /tmp/tmpev2e6_3g
[reverb/cc/platform/default/server.cc:71] Started replay server on port 9999
2025-07-01 19:42:54.321 | INFO | PID:200 | model_file_save.start_actor_process_by_type:776 - learner model_file_save process start, type is 0, no need get mode file from cos
2025-07-01 19:42:54.346 | INFO | PID:274 | monitor_proxy_process.before_run:73 - learner monitor_proxy process start success at pid is 274
2025-07-01 19:42:54.736 | INFO | PID:200 | model_wrapper_common.create_standard_model_wrapper:99 - learner policy_name train_one, algo dynamic_programming, model_wrapper is StandardModelWrapperPytorch
2025-07-01 19:42:54.765 | INFO | PID:200 | on_policy_trainer.before_run:674 - learner train zmq server on learner bind at 0.0.0.0:9997 for aisrv
2025-07-01 19:42:54.768 | INFO | PID:275 | model_file_sync.before_run:189 - learner model_file_sync, use modelpool, use_which_deep_learning_framework is pytorch
2025-07-01 19:42:54.769 | INFO | PID:200 | agent.save_model:108 - learner save model /data/ckpt/gorge_walk_v2_dynamic_programming/model.ckpt-0.npy successfully
2025-07-01 19:42:54.773 | INFO | PID:275 | model_file_sync.before_run:195 - model_file_sync process pid is 275
2025-07-01 19:42:54.777 | INFO | PID:275 | model_file_sync.make_model_dirs:153 - model_file_sync mkdir /data/ckpt/gorge_walk_v2_dynamic_programming/convert_models_learner success
2025-07-01 19:42:54.777 | INFO | PID:276 | monitor_proxy.__init__:36 - learner ppid is 140318018033472
2025-07-01 19:42:54.780 | INFO | PID:275 | monitor_proxy.__init__:36 - learner ppid is 140318018033472
2025-07-01 19:42:54.787 | INFO | PID:276 | model_file_save.before_run:300 - model_file_save process start success at pid 276
2025-07-01 19:42:54.801 | INFO | PID:200 | model_file_sync.push_checkpoint_to_model_pool:560 - model_file_sync push output_file_name /data/ckpt/gorge_walk_v2_dynamic_programming/kaiwu_checkpoint_gorge_walk_v2_dynamic_programming_0.tar.gz key model.ckpt_gorge_walk_v2_dynamic_programming_0 to modelpool success,             total push to modelpool succ cnt is 1             total push to modelpool err cnt is 0
2025-07-01 19:42:54.805 | INFO | PID:200 | on_policy_trainer.before_run:706 - learner train first model file push to modelpool success
2025-07-01 19:42:54.807 | INFO | PID:200 | on_policy_trainer.before_run:739 - learner train process start success at 200, on-policy/off-policy is off-policy, dynamic_programming trainer global step -1.0, load app gorge_walk_v2 algo dynamic_programming model, train_batch_size is 256
2025-07-01 19:42:54.814 | INFO | PID:200 | reverb_dataset_v1.start_background_filler:56 - learner start_background_filler success, reverb.Client connect at localhost:9999
[reverb/cc/client.cc:165] Sampler and server are owned by the same process (200) so Table reverb_replay_buffer_table_0 is accessed directly without gRPC.
2025-07-01 19:43:10.879 | INFO | PID:200 | on_policy_trainer.learner_process_message_by_aisrv:1055 - learner train learner recv process_stop from aisrv 172.19.0.7_0
2025-07-01 19:43:10.883 | INFO | PID:200 | on_policy_trainer.learner_process_message_by_aisrv:1063 - learner train learner send process_stop result to aisrv 172.19.0.7_0
2025-07-01 19:43:10.885 | INFO | PID:200 | on_policy_trainer.learner_get_aisrv_address:937 - learner train get default aisrv_address success, aisrv address: ['127.0.0.1:8000']
2025-07-01 19:43:10.887 | INFO | PID:200 | on_policy_trainer.learner_process_message_by_aisrv:1098 - learner train learner recv aisrv 1 / 1 >= 1, so exit
2025-07-01 19:43:10.889 | INFO | PID:200 | model_file_common.process_stop_write_file:390 - learner process_stop_write_file, error_code is 0
2025-07-01 19:43:36.619 | INFO | PID:276 | model_file_save.handle_sigterm:833 - learner model_file_save 276 start handle SIGTERM.
2025-07-01 19:43:36.845 | INFO | PID:276 | model_file_save.process_model_file:584 - model_file_save zip_file_name /workspace/train/backup_model//gorge_walk_v2-dynamic_programming-1-2025_07_01_19_43_10-6.0.1.zip, zip_json_file_name /workspace/train/backup_model//gorge_walk_v2-dynamic_programming-1-2025_07_01_19_43_10-6.0.1.zip.json copy to /workspace/train/backup_model/ success
